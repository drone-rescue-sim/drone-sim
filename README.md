# ğŸš Drone Simulation with Voice & Natural Language Control

A comprehensive Unity-based drone simulation featuring **voice control** and **natural language processing**. Control your drone using:

ğŸ¤ **Voice Commands**: Speak naturally like "fly forward" or "go up"
âœï¸ **Text Commands**: Type commands through an intuitive UI
ğŸ¤– **LLM Integration**: Powered by Llama2 via Ollama
ğŸ”Š **Whisper AI**: Advanced speech-to-text using OpenAI's Whisper

## ğŸŒŸ Key Features

- **ğŸ¤ Real-time Voice Control** - Speak commands naturally
- **ğŸ¤– AI-Powered Commands** - LLM translates natural language to drone actions
- **ğŸ® Manual Controls** - Traditional arrow key movement
- **ğŸ”„ Seamless Integration** - Unity â†” Python â†” LLM â†” Whisper
- **ğŸ“± User-Friendly UI** - Clean interface for text and voice input
- **âš¡ Fast Processing** - Optimized for real-time interaction

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** with pip
- **Unity 2021+** with Universal Render Pipeline
- **Ollama** (for local LLM processing)
- **ffmpeg** (for audio processing)
- **Llama2 model** (automatically downloaded)
- **Anaconda/Miniconda** (recommended for complete environment)

### 1. Install System Dependencies

#### macOS (with Homebrew)

```bash
# Install Homebrew if not already installed
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install ffmpeg (required for Whisper)
brew install ffmpeg

# Install Anaconda (recommended)
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
bash Miniconda3-latest-MacOSX-arm64.sh
```

#### Linux

```bash
# Install ffmpeg
sudo apt update && sudo apt install ffmpeg

# Install Anaconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
```

### 2. Install Python Dependencies

```bash
# Create conda environment (recommended)
conda create -n drone-sim python=3.11
conda activate drone-sim

# Install dependencies
pip install -r requirements.txt

# Alternative: Install manually
pip install flask requests ollama openai-whisper
```

### 3. Install and Start Ollama

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service (in background)
ollama serve

# In another terminal, pull the Llama2 model
ollama pull llama2
```

### 4. Start Services

```bash
# Using conda environment (recommended)
conda activate drone-sim
python start.py

# Or with specific commands
python start.py start    # Start all services
python start.py stop     # Stop all services
python start.py status   # Check service status
python start.py restart  # Restart all services
```

### 5. Open Unity Project

1. Open Unity Hub
2. Open project: `unity-client/drone-env/`
3. Load scene: `Assets/Scenes/SampleScene.unity`
4. Press Play

### 6. Test the System

```bash
# Run comprehensive tests to verify everything works
python test.py

# Or test specific components
curl http://127.0.0.1:5006/health  # Check service health
```

### 7. Control the Drone

#### ğŸ® Manual Controls (Always Available)

- **â†‘â†“â†â†’** - Move in cardinal directions

#### âœï¸ Text Commands (LLM)

1. Press **TAB** to open command interface
2. Type commands like:
   - "fly forward" â†’ moves forward
   - "go up" â†’ ascends
   - "turn left" â†’ rotates left
   - "stop" â†’ halts all movement

#### ğŸ¤ Voice Commands (Whisper + LLM)

1. Press **TAB** to open command interface
2. Click the **ğŸ¤ Microphone button** (turns red when recording)
3. **Speak naturally** for 5 seconds (auto-stop) or click again to stop
4. Voice is transcribed and processed automatically
5. Try saying: _"Fly forward"_, _"Go back"_, _"Turn around"_ etc.

**ğŸ’¡ Voice commands work exactly like text commands but use your microphone!**

## ğŸ“ Project Structure

```
drone-sim/
â”œâ”€â”€ services/                    # ğŸ Python backend services
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ http_service.py      # ğŸŒ Flask server (text + audio processing)
â”‚   â”‚   â”œâ”€â”€ main.py             # ğŸ¤– LLM command processing logic
â”‚   â”‚   â”œâ”€â”€ test_*.py           # ğŸ§ª Test files for integration
â”‚   â”‚   â””â”€â”€ __pycache__/        # Compiled Python files
â”‚   â””â”€â”€ detection/              # ğŸ‘ï¸ (Future: object detection)
â”‚       â””â”€â”€ main.py
â”‚
â”œâ”€â”€ unity-client/drone-env/     # ğŸ® Unity project
â”‚   â”œâ”€â”€ Assets/
â”‚   â”‚   â”œâ”€â”€ Scenes/
â”‚   â”‚   â”‚   â””â”€â”€ SampleScene.unity    # Main game scene
â”‚   â”‚   â”œâ”€â”€ Scripts/
â”‚   â”‚   â”‚   â”œâ”€â”€ CommandInputUI.cs    # ğŸ¤ UI for text + voice input
â”‚   â”‚   â”‚   â”œâ”€â”€ CommandUISetup.cs    # ğŸ”§ Auto-creates UI elements
â”‚   â”‚   â”‚   â”œâ”€â”€ CommandUIManager.cs  # ğŸ“± Manages UI components
â”‚   â”‚   â”‚   â””â”€â”€ DroneController.cs   # ğŸš Drone movement & integration
â”‚   â”‚   â”œâ”€â”€ Prefabs/
â”‚   â”‚   â”‚   â””â”€â”€ drone Black.prefab   # Drone 3D model
â”‚   â”‚   â””â”€â”€ Settings/           # Unity project settings
â”‚   â”œâ”€â”€ Packages/               # ğŸ“¦ Unity package dependencies
â”‚   â””â”€â”€ ProjectSettings/        # âš™ï¸ Unity project configuration
â”‚
â”œâ”€â”€ venv/                       # ğŸ Python virtual environment
â”œâ”€â”€ requirements.txt            # ğŸ“‹ Python dependencies
â”œâ”€â”€ start.py                     # ğŸš€ Python service startup script
â”œâ”€â”€ test.py                      # ğŸ§ª Comprehensive test suite
â”œâ”€â”€ llm_service.*               # ğŸ“ Service logs and PIDs
â””â”€â”€ README.md                   # ğŸ“– This documentation
```

### ğŸ”§ Core Technologies

- **ğŸ® Unity 2021+** - Game engine and 3D simulation
- **ğŸ Python 3.11+** - Backend processing
- **ğŸŒ Flask** - HTTP server for Unityâ†”Python communication
- **ğŸ¤– Ollama + Llama2** - Local LLM for natural language processing
- **ğŸ¤ OpenAI Whisper** - Speech-to-text transcription
- **ğŸµ ffmpeg** - Audio processing and format conversion
- **ğŸ“¡ HTTP APIs** - Inter-service communication

## ğŸ”§ How It Works

### Architecture Overview

```
ğŸ® Unity Game â”€â”€â”€â”€â”€â”€HTTPâ”€â”€â”€â”€â”€â”€â–º ğŸ Python Flask Server â”€â”€â”€APIâ”€â”€â”€â–º ğŸ¤– Ollama LLM
     â”‚                              â”‚                           â”‚
     â”‚                              â”‚                           â”‚
     â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                     â”‚   Text Commands â”‚         â”‚  Natural Lang   â”‚
     â”‚                     â”‚   (Port 5006)   â”‚         â”‚   Processing    â”‚
     â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚                           â”‚
     â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
ğŸ¤ Voice Recording        â”‚  Audio Commands â”‚         â”‚   Command        â”‚
     â”‚                     â”‚   (Port 5006)   â”‚         â”‚   Generation    â”‚
     â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                              â”‚                           â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€HTTPâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â–¼                           â–¼         â”‚
                           ğŸµ ffmpeg â”€â”€â–º ğŸ”Š Whisper â”€â”€â–º ğŸ“ Transcription  â”‚
                                    â”‚                           â”‚         â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                â–¼
                                                       ğŸš Drone Controller
                                                          (Port 5005)
```

### ğŸ”„ Data Flow

1. **ğŸ¤ Voice Input**: User speaks â†’ Unity Microphone API â†’ WAV file
2. **ğŸ“¤ Audio Upload**: WAV sent to Flask server via HTTP multipart
3. **ğŸµ Audio Processing**: ffmpeg converts â†’ Whisper transcribes â†’ Text output
4. **ğŸ¤– LLM Processing**: Text sent to Ollama â†’ Natural language understanding
5. **ğŸ“¥ Command Execution**: Processed command sent to Unity â†’ Drone movement
6. **ğŸ”„ Feedback Loop**: All steps logged and monitored in real-time

### Key Components

#### 1. ğŸ¤ Voice Recording System (`CommandInputUI.cs`)

- **Unity Microphone API** - Captures audio from system microphone
- **5-second auto-stop** - Prevents endless recordings
- **Real-time feedback** - UI button turns red during recording
- **WAV conversion** - Prepares audio for Whisper processing
- **Error handling** - Graceful fallback if microphone unavailable

#### 2. ğŸ”Š Whisper Audio Processing (`http_service.py`)

- **OpenAI Whisper integration** - Industry-leading speech-to-text
- **Automatic language detection** - Works with multiple languages
- **Confidence scoring** - Quality assessment of transcriptions
- **Model optimization** - Uses 'tiny' model for fast processing
- **Error recovery** - Handles network issues and model downloads

#### 3. ğŸ¤– LLM Command Processing (`main.py`)

- **Ollama + Llama2** - Local AI model, no internet required
- **Natural language understanding** - Translates speech/text to commands
- **Command validation** - Ensures safe and valid drone instructions
- **Extensible prompt engineering** - Easy to add new command types

#### 4. ğŸš Unity Drone Controller (`DroneController.cs`)

- **HTTP server** on port 5005 - Receives processed commands
- **Multi-modal input** - Manual controls + LLM commands + voice
- **Movement interpolation** - Smooth drone animations
- **Command queuing** - Handles multiple commands gracefully
- **Error recovery** - Continues operation despite communication issues

#### 5. ğŸŒ Flask HTTP Service (`http_service.py`)

- **Dual endpoints**: `/process_command` (text) + `/process_audio_command` (voice)
- **Health monitoring** - `/health` endpoint for system status
- **Concurrent processing** - Handles multiple Unity clients
- **Detailed logging** - Comprehensive debugging information
- **Graceful shutdown** - Clean service termination

### ğŸ¯ Supported Commands

#### ğŸ® Manual Controls (Always Available):

- **Arrow Keys**: â†‘â†“â†â†’ for cardinal movement
- **Real-time response** - No processing delay

#### âœï¸ Text Commands (LLM Processing):

**Movement:**

- `"fly forward"`, `"go ahead"`, `"move ahead"` â†’ `move_forward`
- `"go back"`, `"fly backward"`, `"reverse"` â†’ `move_backward`
- `"go left"`, `"fly left"`, `"strafe left"` â†’ `move_left`
- `"go right"`, `"fly right"`, `"strafe right"` â†’ `move_right`

**Vertical Movement:**

- `"go up"`, `"fly up"`, `"ascend"`, `"climb"` â†’ `ascend`
- `"go down"`, `"fly down"`, `"descend"`, `"lower"` â†’ `descend`

**Rotation:**

- `"turn left"`, `"rotate left"`, `"spin left"` â†’ `turn_left`
- `"turn right"`, `"rotate right"`, `"spin right"` â†’ `turn_right`

**Special Commands:**

- `"stop"`, `"halt"`, `"emergency stop"` â†’ `stop`
- `"hover"`, `"stay still"`, `"hold position"` â†’ `stop`

#### ğŸ¤ Voice Commands (Whisper + LLM):

**All text commands work with voice!** Simply speak naturally:

- _"Fly forward please"_ â†’ moves forward
- _"Can you go up a bit?"_ â†’ ascends
- _"Turn around for me"_ â†’ rotates 180Â°
- _"Stop right now"_ â†’ emergency stop

**Voice Features:**

- ğŸ¯ **Natural speech** - No need for exact phrasing
- ğŸŒ **Multi-language** - Automatic language detection
- âš¡ **Real-time processing** - Results in 2-5 seconds
- ğŸ“Š **Confidence scoring** - Quality feedback for transcriptions
- ğŸ”„ **Seamless integration** - Voice â†’ Text â†’ LLM â†’ Drone

**Pro Tips for Voice:**

- Speak clearly but naturally
- Wait for the beep/sound before speaking
- Commands are processed after 5 seconds or manual stop
- Check Unity console for transcription feedback

## ğŸ® Controls

### ğŸ¯ Control Methods Overview

| Method     | Input Type    | Processing    | Speed   | Setup Required |
| ---------- | ------------- | ------------- | ------- | -------------- |
| **Manual** | Arrow Keys    | Direct        | Instant | None           |
| **Text**   | Keyboard + UI | LLM           | 1-2 sec | Ollama running |
| **Voice**  | Microphone    | Whisper + LLM | 3-6 sec | All services   |

### ğŸ® Manual Controls (Always Available)

- **â†‘** - Move forward
- **â†“** - Move backward
- **â†** - Move left
- **â†’** - Move right
- **No dependencies** - Works even if services are down

### âœï¸ Text Commands (LLM Processing)

1. Press **TAB** to open command interface
2. Type natural language: `"fly forward"`, `"go up"`, etc.
3. Press **Enter** or click **Send** button
4. Interface closes automatically
5. Drone moves for 2 seconds, then stops
6. **Result**: Command processed by Llama2, translated to drone action

### ğŸ¤ Voice Commands (Whisper + LLM)

1. Press **TAB** to open command interface
2. Click **ğŸ¤ Microphone** button (turns red when recording)
3. **Speak naturally** for up to 5 seconds
4. Recording auto-stops or click microphone again to stop manually
5. **Processing**: Voice â†’ Whisper transcription â†’ LLM processing â†’ Drone action
6. **Visual feedback**: Button color indicates recording status

### ğŸ›ï¸ UI Controls

- **TAB** - Toggle command interface
- **Enter** - Send text command
- **ğŸ¤ Button** - Start/stop voice recording
- **Send Button** - Send command and close UI
- **Close Button** - Close interface without sending

### âš¡ Performance Expectations

- **Manual**: Instant response
- **Text**: 1-2 seconds (LLM processing)
- **Voice**: 3-6 seconds (Recording + Whisper + LLM)
- **First voice command**: May take longer (Whisper model download)

## ğŸš€ Advanced Setup

### Installing Ollama

```bash
# macOS/Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service (background)
ollama serve

# Pull Llama2 model (happens automatically, but you can pre-download)
ollama pull llama2
```

### Installing ffmpeg (Required for Voice)

#### macOS with Homebrew:

```bash
# Install Homebrew if needed
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install ffmpeg
brew install ffmpeg

# Verify installation
ffmpeg -version
```

#### Linux:

```bash
# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# CentOS/RHEL
sudo yum install ffmpeg
```

#### Windows:

Download from https://ffmpeg.org/download.html and add to PATH

### Python Environment Setup

#### Using Conda (Recommended):

```bash
# Install Miniconda/Anaconda
# macOS ARM64
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh
bash Miniconda3-latest-MacOSX-arm64.sh

# Create environment
conda create -n drone-sim python=3.11
conda activate drone-sim

# Install dependencies
pip install -r requirements.txt
```

#### Using venv:

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt
```

### Manual Service Startup

```bash
# Terminal 1: Start Ollama (if not already running)
ollama serve

# Terminal 2: Activate environment and start LLM service
conda activate drone-sim  # or source venv/bin/activate
cd services/llm
python http_service.py

# Terminal 3: Open Unity project and play
```

### Port Configuration

- **LLM Service**: `http://127.0.0.1:5006`
- **Unity Drone Control**: `http://127.0.0.1:5005`

## ğŸ” Troubleshooting

### Common Issues

#### "LLM service connection failed"

```bash
# Check if services are running
python start.py status

# Restart services
python start.py restart
```

#### "Ollama not found"

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama
ollama serve

# Pull model
ollama pull llama2
```

#### "Port 5006 already in use"

```bash
# Kill existing process
lsof -ti :5006 | xargs kill -9

# Or change port in scripts
```

#### ğŸ¤ Voice Recording Issues

**"Microphone not found"**

```bash
# Check available microphones
python -c "import pyaudio; p = pyaudio.PyAudio(); [print(f'{i}: {p.get_device_info_by_index(i)[\"name\"]}') for i in range(p.get_device_count())]"
```

- Ensure microphone permissions in macOS System Settings
- Try different microphone devices
- Restart Unity after changing microphone settings

**"ffmpeg not found"**

```bash
# macOS
brew install ffmpeg

# Linux
sudo apt install ffmpeg

# Verify
ffmpeg -version
```

**"Whisper model download timeout"**

- First voice command may take 2-5 minutes to download model
- Check internet connection
- Model is cached after first download
- Use `tiny` model for faster processing

**"Audio processing timeout"**

- Increase timeout in `CommandInputUI.cs` if needed
- Check Python service logs for detailed errors
- Ensure sufficient RAM (4GB+ recommended)

#### Unity Issues

**"HttpClient timeout error"**

- Service restarted while Unity was running
- Restart services: `python start.py restart`
- Check service health: `curl http://127.0.0.1:5006/health`

**UI not showing**

- Check Console for errors
- Ensure CommandUIManager is in scene
- Verify TMP Essentials are imported
- Press TAB to manually toggle UI

**Compilation errors**

- Ensure all C# scripts are in Assets/Scripts/
- Check for missing using statements
- Verify Unity version compatibility

### Debug Tips

1. **ğŸ® Check Unity Console** for error messages and transcription feedback
2. **ğŸ Monitor Python logs** in terminal where service is running
3. **ğŸ§ª Run comprehensive tests**: `python test.py`
4. **ğŸ”Š Test voice transcription**:
   ```bash
   # Record a test audio file and test Whisper
   ffmpeg -f avfoundation -i ":0" -t 3 test.wav
   python -c "import whisper; model = whisper.load_model('tiny'); result = model.transcribe('test.wav'); print(result['text'])"
   ```
5. **ğŸ¤– Test LLM directly**:
   ```bash
   curl -X POST http://127.0.0.1:5006/process_command \
        -H "Content-Type: application/json" \
        -d '{"command": "fly forward"}'
   ```
6. **ğŸ’š Check service health**:
   ```bash
   curl http://127.0.0.1:5006/health
   ```
7. **ğŸ¤ Test microphone**:
   ```bash
   # macOS: List available devices
   ffmpeg -f avfoundation -list_devices true -i ""
   ```

## ğŸ“š API Reference

### LLM Service Endpoints

#### POST `/process_command`

Process natural language text commands from Unity.

**Request:**

```json
{
  "command": "fly forward"
}
```

**Response:**

```json
{
  "processed_command": "move_forward",
  "status": "success"
}
```

#### POST `/process_audio_command`

Process voice commands from Unity (WAV audio files).

**Request:** (multipart/form-data)

- `audio`: WAV audio file (voice command)

**Response:**

```json
{
  "transcript": "fly forward",
  "confidence": 0.95,
  "processed_command": "move_forward",
  "status": "success"
}
```

**Error Response:**

```json
{
  "error": "Audio processing timeout"
}
```

#### GET `/health`

Check service health and component availability.

**Response:**

```json
{
  "status": "healthy",
  "service": "drone-llm-service",
  "ollama_available": true,
  "whisper_available": true
}
```

### Unity HTTP Server

The Unity drone controller runs an HTTP server on port 5005 that receives commands from the LLM service.

**Expected format:**

```json
{
  "command": "move_forward"
}
```

**Supported Commands:**

- `move_forward`, `move_backward`, `move_left`, `move_right`
- `ascend`, `descend`
- `turn_left`, `turn_right`
- `stop`

**Expected format:**

```json
{
  "command": "move_forward"
}
```

## ğŸ¯ Next Steps

### Customization Ideas

1. **Add More Commands**: Extend the command list in `http_service.py`
2. **Improve AI**: Fine-tune prompts for better command understanding
3. **Add Voice Control**: Integrate speech-to-text
4. **Multiple Drones**: Support controlling multiple drones
5. **Object Detection**: Add computer vision for obstacle avoidance

### Performance Optimization

- Reduce LLM response time by using smaller models
- Cache common command translations
- Implement command prediction
- Add offline fallback mode

## ğŸ¯ System Architecture Summary

### ğŸ—ï¸ Complete Integration Stack

```
ğŸ¤ User Voice â”€â”€â–º ğŸ® Unity Recording â”€â”€â–º ğŸŒ HTTP Multipart â”€â”€â–º ğŸ Flask Server
                                                                          â”‚
                                                                          â–¼
ğŸµ Audio WAV â”€â”€â–º ğŸµ ffmpeg Processing â”€â”€â–º ğŸ”Š OpenAI Whisper â”€â”€â–º ğŸ“ Transcription
                                                                          â”‚
                                                                          â–¼
ğŸ“„ Text Command â”€â”€â–º ğŸ¤– Ollama Llama2 â”€â”€â–º ğŸ¯ Intent Analysis â”€â”€â–º ğŸš Drone Action
                                                                          â”‚
                                                                          â–¼
ğŸ“¡ HTTP Response â”€â”€â–º ğŸ® Unity Controller â”€â”€â–º ğŸš Drone Movement â”€â”€â–º âœ… User Feedback
```

### âš¡ Performance Characteristics

| Component              | Technology           | Processing Time | Resource Usage    |
| ---------------------- | -------------------- | --------------- | ----------------- |
| **Voice Recording**    | Unity Microphone API | Instant         | Low               |
| **Audio Processing**   | ffmpeg               | <1 sec          | Medium            |
| **Speech Recognition** | OpenAI Whisper       | 2-3 sec         | High (first time) |
| **LLM Processing**     | Ollama Llama2        | 1-2 sec         | Medium            |
| **Drone Control**      | Unity Engine         | Instant         | Low               |

### ğŸ”§ Configuration Files

- **`requirements.txt`** - Python dependencies (Flask, Ollama, OpenAI Whisper)
- **`start_llm_service.sh`** - Service startup with conda environment
- **`http_service.py`** - Main Flask server with dual endpoints
- **`CommandInputUI.cs`** - Unity voice recording and UI management
- **`DroneController.cs`** - Drone movement and HTTP server

## ğŸš€ Future Enhancements

### ğŸ¯ Planned Features

- **ğŸ¥ Object Detection** - Computer vision for obstacle avoidance
- **ğŸ“Š Telemetry Logging** - Flight data recording and analysis
- **ğŸ® Multi-Drone Control** - Coordinate multiple drones
- **ğŸ”„ Offline Mode** - Fallback when services unavailable
- **ğŸŒ Multi-Language Support** - Extended Whisper language models

### ğŸ”§ Technical Improvements

- **âš¡ Performance Optimization** - Reduce latency and resource usage
- **ğŸ›¡ï¸ Error Recovery** - Enhanced fault tolerance
- **ğŸ“± Mobile Support** - iOS/Android deployment
- **â˜ï¸ Cloud Integration** - Remote processing capabilities

## ğŸ“ License & Credits

### License

This project is for educational and research purposes. Feel free to modify and extend!

### ğŸ™ Credits

- **ğŸ¤ OpenAI Whisper** - Industry-leading speech recognition
- **ğŸ¤– Ollama** - Local LLM deployment made easy
- **ğŸ® Unity Technologies** - Powerful game engine
- **ğŸ Python Community** - Flask, requests, and ecosystem

### ğŸ“ Support

- **Unity Console** - Real-time error messages and transcription feedback
- **Python Logs** - Detailed service processing information
- **Health Endpoint** - System status monitoring
- **Debug Tools** - Comprehensive testing utilities

---

**ğŸ‰ Ready to fly?** Your voice-controlled drone is now fully operational with cutting-edge AI integration!</contents>
</xai:function_call_1>Check if there are any linter errors in the README.md file
